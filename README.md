# Sign-Language-Recognition-System

Human-computer interaction is the study of how people interact with computers and to what extent computers is developed for successful interaction with human beings. HCI incorporates multiple disciplines, such as computer science, psychology, human factors, and ergonomics, into one field. It is designed to understand and facilitate better interactions between users and machines.
People affected by speech impairment can't communicate using normal means, they depend on sign language for communication. Sign language is used among everyone who is deaf-muted, but they find it difficult while communicating with normal people. So requirement of a sign language recognition system is a must for speech impaired people.
The objective of the project is to do a real time translation of hand gestures into equivalent text. This system adds various possible languages as compared to existing systems.
This system takes hand gestures as input through video and translates it to text which can be understood by normal users. There will be use of Convolutional Neural Network for classification of hand gestures. By deploying this system, the communication gap between signers and non-signers will be greatly reduced.
